"""
æŠ¥å‘Šç”Ÿæˆå™¨

è´Ÿè´£ç”Ÿæˆè¯¦ç»†çš„è´¨é‡è¯„ä¼°æŠ¥å‘Šï¼Œæ”¯æŒå¤šç§æ ¼å¼è¾“å‡ºã€‚
"""

import logging
from typing import Dict, List, Optional, Any
from datetime import datetime

from .types import (
    QualityAssessment, AssessmentReport, ReportFormat,
    QualityDimension, QualityLevel, Improvement,
    ReportGenerationError
)
from .config import PEQAConfig


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, config: PEQAConfig):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.config = config
        self.logger = logging.getLogger(__name__)

    async def generate_report(self, assessment: QualityAssessment,
                            format: str = "detailed") -> AssessmentReport:
        """
        ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

        Args:
            assessment: è´¨é‡è¯„ä¼°ç»“æœ
            format: æŠ¥å‘Šæ ¼å¼ç±»å‹

        Returns:
            AssessmentReport: ç”Ÿæˆçš„æŠ¥å‘Š
        """
        try:
            # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
            executive_summary = self._generate_executive_summary(assessment)

            # ç”Ÿæˆè¯¦ç»†å†…å®¹
            detailed_content = await self._generate_detailed_content(assessment, format)

            # ç”Ÿæˆæ¨èè¡ŒåŠ¨
            recommendations = self._generate_recommendations(assessment)

            report = AssessmentReport(
                assessment=assessment,
                report_format=ReportFormat.MARKDOWN,  # é»˜è®¤æ ¼å¼
                executive_summary=executive_summary,
                detailed_content=detailed_content,
                recommendations=recommendations,
                language=self.config.get_report_config("language", "zh")
            )

            return report

        except Exception as e:
            self.logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            raise ReportGenerationError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

    def _generate_executive_summary(self, assessment: QualityAssessment) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        quality_level_cn = {
            QualityLevel.EXCELLENT: "ä¼˜ç§€",
            QualityLevel.GOOD: "è‰¯å¥½",
            QualityLevel.FAIR: "ä¸€èˆ¬",
            QualityLevel.POOR: "è¾ƒå·®",
            QualityLevel.VERY_POOR: "å¾ˆå·®"
        }

        level_text = quality_level_cn.get(assessment.quality_level, "æœªçŸ¥")
        score_text = f"{assessment.overall_score:.2f}"

        summary = f"""
# æç¤ºè¯è´¨é‡è¯„ä¼°æ‘˜è¦

**æ€»ä½“è¯„åˆ†**: {score_text}/1.00 ({level_text})
**ç½®ä¿¡åº¦**: {assessment.confidence_level:.2f}
**è¯„ä¼°æ—¶é—´**: {assessment.assessed_at.strftime('%Y-%m-%d %H:%M:%S')}

## å¿«é€Ÿæ´å¯Ÿ
- **ä¸»è¦ä¼˜åŠ¿**: {len(assessment.strengths)}é¡¹
- **æ”¹è¿›ç©ºé—´**: {len(assessment.weaknesses)}é¡¹
- **å»ºè®®è¡ŒåŠ¨**: {len(assessment.improvement_suggestions)}é¡¹

## è´¨é‡æ¦‚å†µ
è¯¥æç¤ºè¯çš„æ•´ä½“è´¨é‡ä¸º{level_text}çº§åˆ«ï¼Œåœ¨{len(assessment.dimension_scores)}ä¸ªè¯„ä¼°ç»´åº¦ä¸­è¡¨ç°å¦‚ä¸‹ï¼š
"""

        # æ·»åŠ ç»´åº¦æ¦‚å†µ
        for dimension, score in assessment.dimension_scores.items():
            dimension_cn = {
                QualityDimension.CLARITY: "æ¸…æ™°åº¦",
                QualityDimension.SPECIFICITY: "å…·ä½“æ€§",
                QualityDimension.COMPLETENESS: "å®Œæ•´æ€§",
                QualityDimension.EFFECTIVENESS: "æœ‰æ•ˆæ€§",
                QualityDimension.ROBUSTNESS: "é²æ£’æ€§"
            }
            dim_name = dimension_cn.get(dimension, dimension.value)
            summary += f"- **{dim_name}**: {score.score:.2f}\n"

        return summary.strip()

    async def _generate_detailed_content(self, assessment: QualityAssessment, format: str) -> str:
        """ç”Ÿæˆè¯¦ç»†å†…å®¹"""
        if format == "detailed":
            return self._generate_detailed_analysis(assessment)
        elif format == "summary":
            return self._generate_summary_analysis(assessment)
        elif format == "compact":
            return self._generate_compact_analysis(assessment)
        else:
            return self._generate_detailed_analysis(assessment)

    def _generate_detailed_analysis(self, assessment: QualityAssessment) -> str:
        """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        content = f"""
# è¯¦ç»†è´¨é‡åˆ†ææŠ¥å‘Š

## æç¤ºè¯å†…å®¹
```
{assessment.prompt_content}
```

## ç»´åº¦è¯„åˆ†è¯¦æƒ…

"""

        dimension_names = {
            QualityDimension.CLARITY: "æ¸…æ™°åº¦",
            QualityDimension.SPECIFICITY: "å…·ä½“æ€§",
            QualityDimension.COMPLETENESS: "å®Œæ•´æ€§",
            QualityDimension.EFFECTIVENESS: "æœ‰æ•ˆæ€§",
            QualityDimension.ROBUSTNESS: "é²æ£’æ€§"
        }

        for dimension, score in assessment.dimension_scores.items():
            dim_name = dimension_names.get(dimension, dimension.value)
            content += f"""
### {dim_name} - {score.score:.2f}/1.00

**è¯„åˆ†ç†ç”±**: {score.reasoning or 'åŸºäºç®—æ³•è‡ªåŠ¨è¯„ä¼°'}

**ä¼˜åŠ¿è¡¨ç°**:
"""
            for evidence in score.evidence:
                content += f"- {evidence}\n"

            if score.issues:
                content += f"""
**å‘ç°é—®é¢˜**:
"""
                for issue in score.issues:
                    content += f"- {issue}\n"

            content += f"\n**ç½®ä¿¡åº¦**: {score.confidence:.2f}\n"

        # æ·»åŠ ä¼˜åŠ¿åˆ†æ
        if assessment.strengths:
            content += """
## ä¼˜åŠ¿åˆ†æ

"""
            for strength in assessment.strengths:
                content += f"- {strength}\n"

        # æ·»åŠ ä¸è¶³åˆ†æ
        if assessment.weaknesses:
            content += """
## æ”¹è¿›ç©ºé—´

"""
            for weakness in assessment.weaknesses:
                content += f"- {weakness}\n"

        # æ·»åŠ æ”¹è¿›å»ºè®®
        if assessment.improvement_suggestions:
            content += """
## æ”¹è¿›å»ºè®®

"""
            for i, improvement in enumerate(assessment.improvement_suggestions, 1):
                priority_cn = {
                    "critical": "ğŸ”´ å…³é”®",
                    "high": "ğŸŸ  é«˜",
                    "medium": "ğŸŸ¡ ä¸­",
                    "low": "ğŸŸ¢ ä½"
                }
                priority_text = priority_cn.get(improvement.priority.value, improvement.priority.value)

                content += f"""
### {i}. {improvement.title} ({priority_text})

**æè¿°**: {improvement.description}

**é¢„æœŸå½±å“**: {improvement.impact_score:.2f}
**å®æ–½éš¾åº¦**: {improvement.difficulty}
**é¢„ä¼°æ”¹è¿›**: {improvement.estimated_improvement:.2f}

"""
                if improvement.before_example and improvement.after_example:
                    content += f"""
**æ”¹è¿›ç¤ºä¾‹**:
- æ”¹è¿›å‰: `{improvement.before_example}`
- æ”¹è¿›å: `{improvement.after_example}`

"""

                if improvement.rationale:
                    content += f"**å®æ–½ç†ç”±**: {improvement.rationale}\n\n"

        # æ·»åŠ æŠ€æœ¯ç»†èŠ‚
        content += f"""
## æŠ€æœ¯ç»†èŠ‚

- **å¤„ç†æ—¶é—´**: {assessment.processing_time_ms}ms
- **æç¤ºè¯é•¿åº¦**: {len(assessment.prompt_content)}å­—ç¬¦
- **è¯æ•°**: {len(assessment.prompt_content.split())}ä¸ª
- **è¯„ä¼°ç»´åº¦**: {len(assessment.dimension_scores)}ä¸ª
- **ç½®ä¿¡åº¦**: {assessment.confidence_level:.2f}

"""

        return content

    def _generate_summary_analysis(self, assessment: QualityAssessment) -> str:
        """ç”Ÿæˆæ‘˜è¦åˆ†æ"""
        content = f"""
# è´¨é‡è¯„ä¼°æ‘˜è¦

**æ•´ä½“è¯„åˆ†**: {assessment.overall_score:.2f}/1.00
**è´¨é‡ç­‰çº§**: {assessment.quality_level.value}

## å„ç»´åº¦è¡¨ç°
"""
        for dimension, score in assessment.dimension_scores.items():
            content += f"- {dimension.value}: {score.score:.2f}\n"

        content += f"""
## ä¸»è¦å‘ç°
- ä¼˜åŠ¿: {len(assessment.strengths)}é¡¹
- é—®é¢˜: {len(assessment.weaknesses)}é¡¹
- å»ºè®®: {len(assessment.improvement_suggestions)}é¡¹

## å»ºè®®è¡ŒåŠ¨
"""
        for improvement in assessment.improvement_suggestions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            content += f"- {improvement.title}\n"

        return content

    def _generate_compact_analysis(self, assessment: QualityAssessment) -> str:
        """ç”Ÿæˆç´§å‡‘åˆ†æ"""
        content = f"""
è¯„åˆ†: {assessment.overall_score:.2f} | ç­‰çº§: {assessment.quality_level.value}
ç»´åº¦: æ¸…æ™°åº¦{assessment.get_dimension_score(QualityDimension.CLARITY):.2f} å…·ä½“æ€§{assessment.get_dimension_score(QualityDimension.SPECIFICITY):.2f} å®Œæ•´æ€§{assessment.get_dimension_score(QualityDimension.COMPLETENESS):.2f}
å»ºè®®: {len(assessment.improvement_suggestions)}é¡¹æ”¹è¿›
"""
        return content.strip()

    def _generate_recommendations(self, assessment: QualityAssessment) -> List[str]:
        """ç”Ÿæˆæ¨èè¡ŒåŠ¨"""
        recommendations = []

        # åŸºäºè´¨é‡ç­‰çº§çš„å»ºè®®
        if assessment.quality_level == QualityLevel.VERY_POOR:
            recommendations.append("ç«‹å³é‡å†™æç¤ºè¯ï¼Œæ˜ç¡®ä»»åŠ¡ç›®æ ‡å’Œå…·ä½“è¦æ±‚")
            recommendations.append("æ·»åŠ è¯¦ç»†çš„èƒŒæ™¯ä¿¡æ¯å’Œçº¦æŸæ¡ä»¶")
        elif assessment.quality_level == QualityLevel.POOR:
            recommendations.append("é‡ç‚¹æ”¹è¿›æ¸…æ™°åº¦å’Œå…·ä½“æ€§")
            recommendations.append("æ·»åŠ å…·ä½“ç¤ºä¾‹å’Œæ ¼å¼è¦æ±‚")
        elif assessment.quality_level == QualityLevel.FAIR:
            recommendations.append("ä¼˜åŒ–è¡¨è¾¾æ–¹å¼ï¼Œå¢å¼ºä¸“ä¸šæ€§")
            recommendations.append("è€ƒè™‘è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†")
        elif assessment.quality_level == QualityLevel.GOOD:
            recommendations.append("è¿›è¡Œç»†èŠ‚ä¼˜åŒ–ä»¥è¾¾åˆ°ä¼˜ç§€æ°´å¹³")
            recommendations.append("å¢å¼ºé²æ£’æ€§è€ƒè™‘")
        else:  # EXCELLENT
            recommendations.append("ä¿æŒå½“å‰è´¨é‡ï¼Œå®šæœŸè¯„ä¼°ä¼˜åŒ–")

        # åŸºäºå…·ä½“é—®é¢˜çš„å»ºè®®
        if assessment.improvement_suggestions:
            top_suggestion = assessment.improvement_suggestions[0]
            recommendations.append(f"ä¼˜å…ˆå¤„ç†: {top_suggestion.title}")

        # åŸºäºç»´åº¦åˆ†æçš„å»ºè®®
        low_score_dimensions = [
            dim for dim, score in assessment.dimension_scores.items()
            if score.score < 0.5
        ]

        if low_score_dimensions:
            dim_names = {
                QualityDimension.CLARITY: "æ¸…æ™°åº¦",
                QualityDimension.SPECIFICITY: "å…·ä½“æ€§",
                QualityDimension.COMPLETENESS: "å®Œæ•´æ€§",
                QualityDimension.EFFECTIVENESS: "æœ‰æ•ˆæ€§",
                QualityDimension.ROBUSTNESS: "é²æ£’æ€§"
            }
            low_dims = [dim_names.get(dim, dim.value) for dim in low_score_dimensions]
            recommendations.append(f"é‡ç‚¹æå‡: {', '.join(low_dims)}")

        return recommendations

    async def export_report(self, report: AssessmentReport,
                          export_format: ReportFormat,
                          file_path: Optional[str] = None) -> str:
        """
        å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report: è¯„ä¼°æŠ¥å‘Š
            export_format: å¯¼å‡ºæ ¼å¼
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            str: å¯¼å‡ºçš„å†…å®¹æˆ–æ–‡ä»¶è·¯å¾„
        """
        try:
            if export_format == ReportFormat.JSON:
                import json
                content = json.dumps(report.model_dump(), indent=2, ensure_ascii=False)
            elif export_format == ReportFormat.HTML:
                content = self._convert_to_html(report)
            elif export_format == ReportFormat.MARKDOWN:
                content = report.detailed_content
            elif export_format == ReportFormat.TEXT:
                content = self._convert_to_text(report)
            elif export_format == ReportFormat.CSV:
                content = self._convert_to_csv(report)
            else:
                raise ReportGenerationError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")

            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                return file_path
            else:
                return content

        except Exception as e:
            raise ReportGenerationError(f"æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {str(e)}")

    def _convert_to_html(self, report: AssessmentReport) -> str:
        """è½¬æ¢ä¸ºHTMLæ ¼å¼"""
        # ç®€åŒ–çš„HTMLè½¬æ¢
        html = f"""
<!DOCTYPE html>
<html>
<head>
    <title>PEQAè´¨é‡è¯„ä¼°æŠ¥å‘Š</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1, h2, h3 {{ color: #333; }}
        .score {{ font-size: 24px; font-weight: bold; color: #007acc; }}
        .dimension {{ margin: 10px 0; }}
        .improvement {{ border-left: 3px solid #007acc; padding-left: 10px; margin: 10px 0; }}
    </style>
</head>
<body>
    <h1>æç¤ºè¯è´¨é‡è¯„ä¼°æŠ¥å‘Š</h1>
    <div class="score">æ€»ä½“è¯„åˆ†: {report.assessment.overall_score:.2f}</div>
    <p><strong>è´¨é‡ç­‰çº§</strong>: {report.assessment.quality_level.value}</p>
    <p><strong>è¯„ä¼°æ—¶é—´</strong>: {report.assessment.assessed_at}</p>

    <h2>æ‰§è¡Œæ‘˜è¦</h2>
    <pre>{report.executive_summary}</pre>

    <h2>è¯¦ç»†å†…å®¹</h2>
    <pre>{report.detailed_content}</pre>
</body>
</html>
"""
        return html

    def _convert_to_text(self, report: AssessmentReport) -> str:
        """è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        text = f"""
PEQAè´¨é‡è¯„ä¼°æŠ¥å‘Š
================

æ€»ä½“è¯„åˆ†: {report.assessment.overall_score:.2f}
è´¨é‡ç­‰çº§: {report.assessment.quality_level.value}
è¯„ä¼°æ—¶é—´: {report.assessment.assessed_at}

æ‰§è¡Œæ‘˜è¦
--------
{report.executive_summary}

è¯¦ç»†å†…å®¹
--------
{report.detailed_content}

æ¨èè¡ŒåŠ¨
--------
"""
        for i, rec in enumerate(report.recommendations, 1):
            text += f"{i}. {rec}\n"

        return text

    def _convert_to_csv(self, report: AssessmentReport) -> str:
        """è½¬æ¢ä¸ºCSVæ ¼å¼"""
        import csv
        import io

        output = io.StringIO()
        writer = csv.writer(output)

        # å†™å…¥æ ‡é¢˜è¡Œ
        writer.writerow(['æŒ‡æ ‡', 'æ•°å€¼', 'è¯´æ˜'])

        # å†™å…¥åŸºæœ¬ä¿¡æ¯
        writer.writerow(['æ€»ä½“è¯„åˆ†', f"{report.assessment.overall_score:.2f}", '0-1åˆ†åˆ¶'])
        writer.writerow(['è´¨é‡ç­‰çº§', report.assessment.quality_level.value, ''])
        writer.writerow(['ç½®ä¿¡åº¦', f"{report.assessment.confidence_level:.2f}", ''])

        # å†™å…¥ç»´åº¦è¯„åˆ†
        for dimension, score in report.assessment.dimension_scores.items():
            writer.writerow([f'{dimension.value}è¯„åˆ†', f"{score.score:.2f}", score.reasoning or ''])

        # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
        writer.writerow(['ä¼˜åŠ¿æ•°é‡', len(report.assessment.strengths), ''])
        writer.writerow(['é—®é¢˜æ•°é‡', len(report.assessment.weaknesses), ''])
        writer.writerow(['å»ºè®®æ•°é‡', len(report.assessment.improvement_suggestions), ''])
        writer.writerow(['å¤„ç†æ—¶é—´', f"{report.assessment.processing_time_ms}ms", ''])

        return output.getvalue()